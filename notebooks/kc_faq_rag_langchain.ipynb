{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Basic RAG QA with Langchain\n",
    "This notebook demonstrates how to implement a basic Retrieval-Augmented Generation (RAG) chain using our FAQ data. The overall approach is as follows:\n",
    "1. Load FAQ Data & Structure Metadata\n",
    "2. Create Embeddings for the FAQ Data using Amazon's Titan Embeddings model, and save these embeddings locally using Chroma.\n",
    "3. Create a Question Answering (QA) chain which retrieves context based on the embeddings saved in Chroma, serving these as context to the Amazon Titan Express LLM to answer the provided user prompt.\n",
    "4. Format the response so that source materials can be cited.\n",
    "\n",
    "This implementation mostly follows these Langchain tutorials:\n",
    "- https://python.langchain.com/docs/modules/data_connection/document_loaders/json#using-jsonloader\n",
    "-  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metadata extraction function so we can filter on sections and return deep links as sources\n",
    "def metadata_func(record: dict, metadata: dict) -> dict:\n",
    "    metadata[\"section\"] = record.get(\"section\")\n",
    "    metadata[\"source\"] = record.get(\"deep_link\")\n",
    "    \n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import JSON FAQ File using JSONLoader\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from pprint import pprint\n",
    "\n",
    "file_path='../data/processed/faq_data/EN_SYR.json'\n",
    "\n",
    "loader = JSONLoader(\n",
    "    file_path=file_path,\n",
    "    jq_schema=\".[]\",\n",
    "    content_key=\"answer\",\n",
    "    metadata_func=metadata_func\n",
    ")\n",
    "\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "embeddings = BedrockEmbeddings(\n",
    "    model_id=\"amazon.titan-embed-text-v1\", region_name=\"us-east-1\"\n",
    ")\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=data, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_community.llms import Bedrock\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Retrieve and generate answers using relevant FAQs\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer from the provided context, just say that your training materials don't include this information, don't try to make up an answer.\n",
    "Keep the answer as concise as possible.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "custom_rag_prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "llm = Bedrock(model_id=\"amazon.titan-text-express-v1\", model_kwargs={\"maxTokenCount\": 4000})\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "To get married in Turkey, you must meet the following legal requirements, which include being at least 18 years old and having the legal capacity to marry. You can apply for a marriage license at the local civil registry office\n",
      "office. You will need to provide certain documents, such as your passport, birth certificate, and proof of divorce or death of your previous spouse, if applicable. You will also need to attend a wedding ceremony conducted by a religious official or a civil official.\n",
      "Sources: https://multecihaklari.info/services/marriage-divorce/?section=questions&question=6; https://multecihaklari.info/services/marriage-divorce/?section=questions&question=2\n"
     ]
    }
   ],
   "source": [
    "def extract_unique_urls(response):\n",
    "    unique_urls = set()  # Use a set to store unique URLs\n",
    "    \n",
    "    # Iterate through each document in the 'context'\n",
    "    for document in response['context']:\n",
    "        source_url = document.metadata['source']  # Extract the 'source' URL\n",
    "        unique_urls.add(source_url)  # Add the URL to the set\n",
    "    \n",
    "    # Convert the set of unique URLs to a string\n",
    "    urls_string = '; '.join(unique_urls)\n",
    "    \n",
    "    return urls_string\n",
    "\n",
    "response = rag_chain_with_source.invoke(\"I want to be married in Turkey. What are the requirements, and where do I apply?\")\n",
    "print(response[\"answer\"])\n",
    "print(f\"Sources: {extract_unique_urls(response)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
