{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Basic RAG QA with Langchain\n",
    "This notebook demonstrates how to implement a basic Retrieval-Augmented Generation (RAG) chain using Turkish legislation data. The overall approach is as follows:\n",
    "1. Load Legislation Data & Structure Metadata\n",
    "2. Create Embeddings for the Legislation Data using Amazon's Titan Embeddings model, and save these embeddings locally using Chroma.\n",
    "3. Create a Question Answering (QA) chain which retrieves context based on the embeddings saved in Chroma, serving these as context to the Amazon Titan Express LLM to answer the provided user prompt.\n",
    "4. Format the response so that source materials can be cited.\n",
    "\n",
    "This implementation mostly follows these Langchain tutorials:\n",
    "- https://python.langchain.com/docs/modules/data_connection/document_loaders/json#using-jsonloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metadata extraction function so we can return links as sources\n",
    "def metadata_func(record: dict, metadata: dict) -> dict:\n",
    "    metadata[\"legislation_title\"] = record.get(\"title\")\n",
    "    metadata[\"source\"] = record.get(\"url\")\n",
    "    \n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import JSON FAQ File using JSONLoader\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from pprint import pprint\n",
    "\n",
    "file_path='../data/processed/legislation_data/National_Legislation_Content_TR.json'\n",
    "\n",
    "loader = JSONLoader(\n",
    "    file_path=file_path,\n",
    "    jq_schema=\".[]\",\n",
    "    content_key=\"content\",\n",
    "    text_content=False, # Need this because content is a list, not string\n",
    "    metadata_func=metadata_func\n",
    ")\n",
    "\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_docs(documents,chunk_size=4000,chunk_overlap=20):\n",
    "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "  docs = text_splitter.split_documents(documents)\n",
    "  return docs\n",
    "\n",
    "docs = split_docs(data)\n",
    "\n",
    "\n",
    "embeddings = BedrockEmbeddings(\n",
    "    model_id=\"amazon.titan-embed-text-v1\", region_name=\"us-east-1\"\n",
    ")\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=docs, embedding=embeddings, persist_directory='./data/processed/legislation_data/vectordata')\n",
    "vectorstore.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_community.llms import Bedrock\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Retrieve and generate answers using relevant FAQs\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer from the provided context, just say that your training materials don't include this information, don't try to make up an answer.\n",
    "Keep the answer as concise as possible.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "prompt_template_TR = \"\"\"Aşağıdaki bilgilerle kulanarak soran soruyu cevaplayın. Eğer mecvut bilgileriyle soruyu cevaplamak mümkün değilse, mevcut bilgilerde sorunun cevabı bulunmadğını açıklayın.\n",
    "\n",
    "{context}\n",
    "\n",
    "Soru: {question}\n",
    "\n",
    "Yardımcı cevabı:\"\"\"\n",
    "custom_rag_prompt = PromptTemplate.from_template(prompt_template_TR)\n",
    "\n",
    "# Instantiate Claude 2.1 with parameters passed via the CreateInferenceModifier helper\n",
    "from utils import CreateInferenceModifier # Import the function from utils.py\n",
    "\n",
    "# Define the universal set of modifier parameters\n",
    "modifiers = {\"max_tokens\": 20000,\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 1,\n",
    "    \"stop_sequences\": [\"\\n\\nHuman\"],\n",
    "    }\n",
    "\n",
    "llm = Bedrock(model_id=\"anthropic.claude-v2:1\", model_kwargs=CreateInferenceModifier(\"claude\", modifiers))\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Üzgünüm, verilen bilgiler arasında sığınmacı çocukları ile ilgili mevzuatı veya bunların hangi bölümlerini kapsadığına dair bir bilgi bulunmamaktadır. Verilen bilgiler, Türkiye'de çocuk adalet sistemi, çocuk mahkemeleri, çocuk savcılıkları, çocuk koruma kanunu gibi konularla ilgili hükümleri içermektedir. Sığınmacı çocuklara özgü bir bilgi yer almamaktadır. Dolayısıyla mevcut bilgilerle bu sorunun cevaplanması mümkün değildir. Özür dilerim.\n",
      "Sources: https://multecihukuku.net/ulusal-mevzuat/cocuk-koruma-kanununun-uygulanmasina-iliskin-usul-ve-esaslar-hakkinda-yonetmelik/; https://multecihukuku.net/ulusal-mevzuat/cocuk-koruma-hizmetleri-planlama-ve-cocuk-bakim-kuruluslarinin-calisma-usul-ve-esaslari-hakkinda-yonetmelik/; https://multecihukuku.net/ulusal-mevzuat/cocuk-koruma-kanunu/\n"
     ]
    }
   ],
   "source": [
    "# Define a function to extract unique URLs used in the retrieved source materials.\n",
    "def extract_unique_urls(response):\n",
    "    unique_urls = set()  # Use a set to store unique URLs\n",
    "    \n",
    "    # Iterate through each document in the 'context'\n",
    "    for document in response['context']:\n",
    "        source_url = document.metadata['source']  # Extract the 'source' URL\n",
    "        unique_urls.add(source_url)  # Add the URL to the set\n",
    "    \n",
    "    # Convert the set of unique URLs to a string\n",
    "    urls_string = '; '.join(unique_urls)\n",
    "    \n",
    "    return urls_string\n",
    "\n",
    "# Invoke the chain and print the response and sources.\n",
    "response = rag_chain_with_source.invoke(\"Türkiye'de sığınmacı çocukları ile ilgi mevzuatı hangi kanunları ve bunların hangi bölümleri kapsar?\")\n",
    "print(response[\"answer\"])\n",
    "print(f\"Sources: {extract_unique_urls(response)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
